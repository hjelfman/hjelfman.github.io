---
layout: post
title: "slopworld"
date: 2025-06-27
categories: misc
---

as a civilization, our main obsession is efficiency. this is a good goal, given that we live in a world with limited resources, we ought to reduce waste and maximize the usage of what we can. however, targeting any metric results in significant externalities which need to be managed.

generative ai gives its users the promise of efficiency. in the use case of writing, it reduces time spent writing cover letters, emails, and essays, in research it reduces the amount of time spent compiling and synthesizing information, in image generation the amount of time perfecting a skill in a niche style and so on. the losses are innumerable.

first, these tools do not synthesize new information, contrary to the entire objective of writing. these models are essentially markov chains. given an input, they can generate a sequence of text which is likely to satisfy the users' wants. the veracity of this text not taken into consideration; oftentimes what a user wants is different from what they need. at no point is there an active sentience involved for cover letters, where minimal input thought is required, this is still self-defeating â€“ the model is likely to generate the average sufficient letter rather than one which accurately reflects the role and resume of the user. for essays and original writing, the point of these works is the creation of a new synthesis or work. outsourcing this process dodges the entire point: no originality occurs. the same for AI-generated images. what is lost is the entire reason why these goods are created.

rather, the items generated are emblematic of what they seek to fulfill rather than becoming an actual answer. they are a sign, or placeholder for, the real thing. in other words, the apex of hyper-reality, in which all real things have been replaced with signs for them. a world of references. we cannot live off substitutes alone, we must eat real food.

second, any technology we use becomes an extension of ourselves. actions are manifestations of will. any tool which turns thoughts to deed affects the form these deeds take and in turn feeds back to the brain. when I write in this journal, my thoughts are recorded on the page and I no longer need to remember them, just that they are located in a third place. the paper is a neural outgrowth. when one reads an argument and accepts it, they allow the author of the argument to perform the mental machinations for them such that they may assume the conclusions of the argument. this is not necessarily a bad thing, some mental processes are costly and ought to be outsourced if unnecessary, but some are critical.

llms promise the acceleration of cognition, that one may bypass the effort involved in pursuing linguistic and logical tasks. by avoiding such effort we let our faculties atrophy. in writing an email one may employ minor persuasive or literary skills, a microscopic exercise in communication. it may save time to have it written, but these communicative skills lay dormant and as a consequence, the user becomes poorer in all interactions which use them. the same is true in research and synthesis. regardless of at the veracity of the information produced by such models, any such dependence on these models depletes the user of an opportunity to practice these skills, such that what the user produces without an llm down the line is deficient in a quality it would otherwise have. it is not enough that these models produce questionable content; it leaves its users to do the same in perpetuity as a linguistic prion.

finally, any tools which promise the use of a semi-thinking machine are deeply suspect. this is an argument stemming from personal morals and is separable from the other two. the use of tools involves prompting, requiring a machine which appears semi-conscious to produce a result, hiring the thinking-machine into a task. if one believes that these machines are truly conscious, the use of such transforms a thinking other into a means. and even if one does not believe these machines to be alive, the use of such transforms the quality of thinking into a commodifiable object which can be exchanged, knocking it down from its place as a uniquely human endeavor. in my eyes, this leaves humanity all the poorer, incorrectly indulging a trait belong to us, the substitution of cognition for a faux version of it allows us to devalue our peers. why depend on one another when we can rely on something reliable and deterministic?

the outcome of all of this is a world replaced by saccharin-versions of itself, objects reduced to signs signifying nothing, an ultimately decontextualized society where culture washes over itself and recombines. all colors mixed do not result in a rainbow but rather a grey paste. these models digest and output the beauty of our world in the same way.
